{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pymilvus milvus langchain sentence-transformers tiktoken octoai-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms.octoai_endpoint import OctoAIEndpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"OCTOAI_API_TOKEN\"] = os.getenv(\"OCTOAI_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n Instruction:\\n{question}\\n Response: \"\"\"\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OctoAIEndpoint(\n",
    "    endpoint_url=\"https://text.octoai.run/v1/chat/completions\",\n",
    "    model_kwargs={\n",
    "        \"model\": \"mixtral-8x7b-instruct-fp16\",\n",
    "        \"max_tokens\": 128,\n",
    "        \"presence_penalty\": 0,\n",
    "        \"temperature\": 0.01,\n",
    "        \"top_p\": 0.9,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant. Keep your responses limited to one short paragraph if possible.\",\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Leonardo da Vinci (1452-1519) was an Italian polymath who is often regarded as one of the greatest painters in history. He is also celebrated for his technological ingenuity, scientific curiosity, and philosophical wisdom. Da Vinci is widely known for his masterpieces such as 'The Last Supper' and 'Mona Lisa.' As an artist, scientist, mathematician, engineer, inventor, anatomist, geologist, cartographer, botanist, musician, and writer, da Vinci embodied the Renaissance ideal. His thirst for\n"
     ]
    }
   ],
   "source": [
    "question = \"Who was leonardo davinci?\"\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "print(llm_chain.invoke(question)[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\SAHIL\\Softwares\\octoai_milvus\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from milvus import default_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_server.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Boston.txt',\n",
       " 'Cambridge, Massachusetts.txt',\n",
       " 'Chicago.txt',\n",
       " 'Houston.txt',\n",
       " 'San Francisco.txt',\n",
       " 'Seattle.txt',\n",
       " 'Toronto.txt',\n",
       " 'Washington, D.C..txt']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir(\"./data\")\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_texts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 713, which is longer than the specified 512\n",
      "Created a chunk of size 543, which is longer than the specified 512\n",
      "Created a chunk of size 838, which is longer than the specified 512\n",
      "Created a chunk of size 666, which is longer than the specified 512\n",
      "Created a chunk of size 690, which is longer than the specified 512\n",
      "Created a chunk of size 758, which is longer than the specified 512\n",
      "Created a chunk of size 1142, which is longer than the specified 512\n",
      "Created a chunk of size 1014, which is longer than the specified 512\n",
      "Created a chunk of size 531, which is longer than the specified 512\n",
      "Created a chunk of size 1038, which is longer than the specified 512\n",
      "Created a chunk of size 585, which is longer than the specified 512\n",
      "Created a chunk of size 716, which is longer than the specified 512\n",
      "Created a chunk of size 631, which is longer than the specified 512\n",
      "Created a chunk of size 972, which is longer than the specified 512\n",
      "Created a chunk of size 696, which is longer than the specified 512\n",
      "Created a chunk of size 737, which is longer than the specified 512\n",
      "Created a chunk of size 785, which is longer than the specified 512\n",
      "Created a chunk of size 547, which is longer than the specified 512\n",
      "Created a chunk of size 1299, which is longer than the specified 512\n",
      "Created a chunk of size 597, which is longer than the specified 512\n",
      "Created a chunk of size 524, which is longer than the specified 512\n",
      "Created a chunk of size 535, which is longer than the specified 512\n",
      "Created a chunk of size 843, which is longer than the specified 512\n",
      "Created a chunk of size 746, which is longer than the specified 512\n",
      "Created a chunk of size 887, which is longer than the specified 512\n",
      "Created a chunk of size 662, which is longer than the specified 512\n",
      "Created a chunk of size 515, which is longer than the specified 512\n",
      "Created a chunk of size 615, which is longer than the specified 512\n",
      "Created a chunk of size 739, which is longer than the specified 512\n",
      "Created a chunk of size 837, which is longer than the specified 512\n",
      "Created a chunk of size 640, which is longer than the specified 512\n",
      "Created a chunk of size 944, which is longer than the specified 512\n",
      "Created a chunk of size 656, which is longer than the specified 512\n",
      "Created a chunk of size 1213, which is longer than the specified 512\n",
      "Created a chunk of size 1084, which is longer than the specified 512\n",
      "Created a chunk of size 519, which is longer than the specified 512\n",
      "Created a chunk of size 778, which is longer than the specified 512\n",
      "Created a chunk of size 624, which is longer than the specified 512\n",
      "Created a chunk of size 614, which is longer than the specified 512\n",
      "Created a chunk of size 995, which is longer than the specified 512\n",
      "Created a chunk of size 608, which is longer than the specified 512\n",
      "Created a chunk of size 1045, which is longer than the specified 512\n",
      "Created a chunk of size 545, which is longer than the specified 512\n",
      "Created a chunk of size 783, which is longer than the specified 512\n",
      "Created a chunk of size 546, which is longer than the specified 512\n",
      "Created a chunk of size 559, which is longer than the specified 512\n",
      "Created a chunk of size 716, which is longer than the specified 512\n",
      "Created a chunk of size 869, which is longer than the specified 512\n",
      "Created a chunk of size 542, which is longer than the specified 512\n",
      "Created a chunk of size 921, which is longer than the specified 512\n",
      "Created a chunk of size 891, which is longer than the specified 512\n",
      "Created a chunk of size 542, which is longer than the specified 512\n",
      "Created a chunk of size 762, which is longer than the specified 512\n",
      "Created a chunk of size 567, which is longer than the specified 512\n",
      "Created a chunk of size 584, which is longer than the specified 512\n",
      "Created a chunk of size 701, which is longer than the specified 512\n",
      "Created a chunk of size 670, which is longer than the specified 512\n",
      "Created a chunk of size 648, which is longer than the specified 512\n",
      "Created a chunk of size 894, which is longer than the specified 512\n",
      "Created a chunk of size 770, which is longer than the specified 512\n",
      "Created a chunk of size 797, which is longer than the specified 512\n",
      "Created a chunk of size 840, which is longer than the specified 512\n",
      "Created a chunk of size 834, which is longer than the specified 512\n",
      "Created a chunk of size 776, which is longer than the specified 512\n",
      "Created a chunk of size 695, which is longer than the specified 512\n",
      "Created a chunk of size 1956, which is longer than the specified 512\n",
      "Created a chunk of size 659, which is longer than the specified 512\n",
      "Created a chunk of size 1033, which is longer than the specified 512\n",
      "Created a chunk of size 626, which is longer than the specified 512\n",
      "Created a chunk of size 970, which is longer than the specified 512\n",
      "Created a chunk of size 714, which is longer than the specified 512\n",
      "Created a chunk of size 672, which is longer than the specified 512\n",
      "Created a chunk of size 600, which is longer than the specified 512\n",
      "Created a chunk of size 567, which is longer than the specified 512\n",
      "Created a chunk of size 684, which is longer than the specified 512\n",
      "Created a chunk of size 875, which is longer than the specified 512\n",
      "Created a chunk of size 807, which is longer than the specified 512\n",
      "Created a chunk of size 730, which is longer than the specified 512\n",
      "Created a chunk of size 992, which is longer than the specified 512\n",
      "Created a chunk of size 793, which is longer than the specified 512\n",
      "Created a chunk of size 677, which is longer than the specified 512\n",
      "Created a chunk of size 530, which is longer than the specified 512\n",
      "Created a chunk of size 592, which is longer than the specified 512\n",
      "Created a chunk of size 583, which is longer than the specified 512\n",
      "Created a chunk of size 575, which is longer than the specified 512\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    with open(f\"./data/{file}\", encoding=\"utf8\") as f:\n",
    "        file_text = f.read()\n",
    "    text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=512, chunk_overlap=64, \n",
    "    )\n",
    "    texts = text_splitter.split_text(file_text)\n",
    "    for i, chunked_text in enumerate(texts):\n",
    "        file_texts.append(Document(page_content=chunked_text, \n",
    "                metadata={\"doc_title\": file.split(\".\")[0], \"chunk_num\": i}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Milvus.__init__() got an unexpected keyword argument 'filter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m \u001b[43mMilvus\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_texts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconnection_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlocalhost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mport\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m19530\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfilter_test\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdoc_title == \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBoston\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\SAHIL\\Softwares\\octoai_milvus\\venv\\Lib\\site-packages\\langchain_core\\vectorstores.py:528\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[1;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[0;32m    526\u001b[0m texts \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m    527\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m--> 528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\SAHIL\\Softwares\\octoai_milvus\\venv\\Lib\\site-packages\\langchain_community\\vectorstores\\milvus.py:980\u001b[0m, in \u001b[0;36mMilvus.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, collection_name, connection_args, consistency_level, index_params, search_params, drop_old, ids, **kwargs)\u001b[0m\n\u001b[0;32m    977\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    978\u001b[0m     auto_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 980\u001b[0m vector_db \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconnection_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconsistency_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsistency_level\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43msearch_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    987\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_old\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_old\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    988\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauto_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    989\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    990\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    991\u001b[0m vector_db\u001b[38;5;241m.\u001b[39madd_texts(texts\u001b[38;5;241m=\u001b[39mtexts, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, ids\u001b[38;5;241m=\u001b[39mids)\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vector_db\n",
      "\u001b[1;31mTypeError\u001b[0m: Milvus.__init__() got an unexpected keyword argument 'filter'"
     ]
    }
   ],
   "source": [
    "vector_store = Milvus.from_documents(\n",
    "    file_texts,\n",
    "    embedding=embeddings,\n",
    "    connection_args={\"host\": \"localhost\", \"port\": 19530},\n",
    "    collection_name=\"filter_test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"Boston (US: ), officially the City of Boston, is the capital and most populous city of the U.S. state of Massachusetts, and the cultural and financial center of New England in the Northeastern United States, with an area of 48.4 sq mi (125 km2) and a population of 675,647 in 2020. Greater Boston metropolitan statistical area is the eleventh-largest in the country.Boston is one of the United States's oldest municipalities. It was founded on the Shawmut Peninsula in 1630 by Puritan settlers from Boston, Lincolnshire. During the American Revolution, Boston was the location of several key events, including the Boston Massacre, the Boston Tea Party, the hanging of Paul Revere's lantern signal in Old North Church, the Battle of Bunker Hill, and the siege of Boston. Following American independence from Great Britain, the city continued to play an important role as a port, manufacturing hub, and center for education and culture. The city has expanded beyond the original peninsula through land reclamation and municipal annexation. It now attracts many tourists, with Faneuil Hall alone drawing more than 20 million visitors per year. Boston's many firsts include the United States' first public park (Boston Common, 1634), the first public school (Boston Latin School, 1635), the first subway system (Tremont Street subway, 1897), and the first large public library (Boston Public Library, 1848).\\nIn the 21st century, Boston emerged as a global leader in higher education and academic research. Greater Boston's many colleges and universities include Harvard University and MIT, both located in suburban Cambridge and both routinely included among the world's most highly ranked universities. The city is also a national leader in scientific research, law, medicine, engineering, and business. With nearly 5,000 startup companies, the city is considered a global pioneer in innovation and entrepreneurship. Boston's economic base also includes finance, professional and business services, biotechnology, information technology, and government activities. Households in the city claim the highest average rate of philanthropy in the United States. Boston businesses and institutions rank among the top in the country for environmental sustainability and new investment.\\n\\n\\n== History ==\", metadata={'doc_title': 'Boston', 'chunk_num': 0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "# https://www.e2enetworks.com/blog/implementing-a-rag-pipeline-with-mixtral-8x7b\n",
    "# retriever = db.as_retriever(\n",
    "#    search_type=\"similarity\",\n",
    "#    search_kwargs={'k': 20}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The city of Seattle has a population of 749,256 as of 2022, and the Seattle metropolitan area has a population of 4.02 million.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"How big is the city of Seattle?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make this a bit more fun and showcase the multilingual capabilities of Mixtal which really outshine other open source models\n",
    "\n",
    "# Our Vector DB is populated with entries from english text - even the embedding model we're using here, GTE-Large\n",
    "# works best on english text. However Mixtral has good mutlilingual capabilities in French, German, Spanish and Italian.\n",
    "# So what we'll do is ask the assistant to only answer in french in the system and user prompt. RAG here is performed based on \n",
    "# english text, but upon producing the user response, the Mixtral LLM will generate tokens in a different language here (french)\n",
    "french_llm = OctoAIEndpoint(\n",
    "    endpoint_url=\"https://text.octoai.run/v1/chat/completions\",\n",
    "    model_kwargs={\n",
    "        \"model\": \"mixtral-8x7b-instruct-fp16\",\n",
    "        \"max_tokens\": 128,\n",
    "        \"presence_penalty\": 0,\n",
    "        \"temperature\": 0.1,\n",
    "        \"top_p\": 0.9,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant who responds in French and not in English.\",\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    ")\n",
    "\n",
    "french_template = \"\"\"Answer the question in French based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "french_prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "french_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | french_prompt\n",
    "    | french_llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Based on the document provided, the city of Seattle is the most populous city in both the state of Washington and the Pacific Northwest region of North America with a population of 749,256 in 2022. The Seattle metropolitan area's population is 4.02 million, making it the 15th-largest in the United States.\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "french_chain.invoke(\"How big is the city of Seattle?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_server.stop()\n",
    "# default_server.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
